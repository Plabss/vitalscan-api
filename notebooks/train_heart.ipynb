{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec140f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ec21aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "   id  age     sex    dataset               cp  trestbps   chol    fbs  \\\n",
      "0   1   63    Male  Cleveland   typical angina     145.0  233.0   True   \n",
      "1   2   67    Male  Cleveland     asymptomatic     160.0  286.0  False   \n",
      "2   3   67    Male  Cleveland     asymptomatic     120.0  229.0  False   \n",
      "3   4   37    Male  Cleveland      non-anginal     130.0  250.0  False   \n",
      "4   5   41  Female  Cleveland  atypical angina     130.0  204.0  False   \n",
      "\n",
      "          restecg  thalch  exang  oldpeak        slope   ca  \\\n",
      "0  lv hypertrophy   150.0  False      2.3  downsloping  0.0   \n",
      "1  lv hypertrophy   108.0   True      1.5         flat  3.0   \n",
      "2  lv hypertrophy   129.0   True      2.6         flat  2.0   \n",
      "3          normal   187.0  False      3.5  downsloping  0.0   \n",
      "4  lv hypertrophy   172.0  False      1.4    upsloping  0.0   \n",
      "\n",
      "                thal  num  \n",
      "0       fixed defect    0  \n",
      "1             normal    2  \n",
      "2  reversable defect    1  \n",
      "3             normal    0  \n",
      "4             normal    0  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "DATA_PATH = '../datasets/heart_disease_uci.csv'\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv(DATA_PATH)\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{DATA_PATH}' not found.\")\n",
    "    print(\"Please download the dataset and place it in the '../datasets' directory.\")\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cbe320c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d610730e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>thalch</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>920.000000</td>\n",
       "      <td>920.000000</td>\n",
       "      <td>861.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>920.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>460.500000</td>\n",
       "      <td>53.510870</td>\n",
       "      <td>132.132404</td>\n",
       "      <td>199.130337</td>\n",
       "      <td>137.545665</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.676375</td>\n",
       "      <td>0.995652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>265.725422</td>\n",
       "      <td>9.424685</td>\n",
       "      <td>19.066070</td>\n",
       "      <td>110.780810</td>\n",
       "      <td>25.926276</td>\n",
       "      <td>1.091226</td>\n",
       "      <td>0.935653</td>\n",
       "      <td>1.142693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>-2.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>230.750000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>460.500000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>223.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>690.250000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>920.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>603.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id         age    trestbps        chol      thalch     oldpeak  \\\n",
       "count  920.000000  920.000000  861.000000  890.000000  865.000000  858.000000   \n",
       "mean   460.500000   53.510870  132.132404  199.130337  137.545665    0.878788   \n",
       "std    265.725422    9.424685   19.066070  110.780810   25.926276    1.091226   \n",
       "min      1.000000   28.000000    0.000000    0.000000   60.000000   -2.600000   \n",
       "25%    230.750000   47.000000  120.000000  175.000000  120.000000    0.000000   \n",
       "50%    460.500000   54.000000  130.000000  223.000000  140.000000    0.500000   \n",
       "75%    690.250000   60.000000  140.000000  268.000000  157.000000    1.500000   \n",
       "max    920.000000   77.000000  200.000000  603.000000  202.000000    6.200000   \n",
       "\n",
       "               ca         num  \n",
       "count  309.000000  920.000000  \n",
       "mean     0.676375    0.995652  \n",
       "std      0.935653    1.142693  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    1.000000  \n",
       "75%      1.000000    2.000000  \n",
       "max      3.000000    4.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c8b10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "age           0\n",
       "sex           0\n",
       "dataset       0\n",
       "cp            0\n",
       "trestbps     59\n",
       "chol         30\n",
       "fbs          90\n",
       "restecg       2\n",
       "thalch       55\n",
       "exang        55\n",
       "oldpeak      62\n",
       "slope       309\n",
       "ca          611\n",
       "thal        486\n",
       "num           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95d48126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape after before NA: (920, 15)\n",
      "Dataset shape after dropping NA: (299, 15)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values and non-predictive columns\n",
    "if data is not None:\n",
    "    print(f\"Dataset shape after before NA: {data.shape}\")\n",
    "    data = data.dropna()\n",
    "    print(f\"Dataset shape after dropping NA: {data.shape}\")\n",
    "    \n",
    "    # Drop 'id' and 'origin' if they exist\n",
    "    data = data.drop(['id'], axis=1, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "481a34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features 'X' and target 'y'\n",
    "if data is not None:\n",
    "    try:\n",
    "        X_raw = data.drop('num', axis=1)\n",
    "        y_raw = data['num']\n",
    "        \n",
    "        # Convert target 'num' (0=no, 1-4=yes) to binary (0=no, 1=yes)\n",
    "        y = y_raw.astype(float).apply(lambda x: 1 if x > 0 else 0)\n",
    "    except KeyError:\n",
    "        print(\"Error: Could not find 'num' column. Please check your CSV.\")\n",
    "        data = None # Stop execution if key column is missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a4144ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features converted.\n",
      "New feature shape: (299, 28)\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical features to numeric using get_dummies\n",
    "if data is not None:\n",
    "    X = pd.get_dummies(X_raw) \n",
    "    print(\"Categorical features converted.\")\n",
    "    print(f\"New feature shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f90cd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 239, Test samples: 60\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "if data is not None:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5a9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scaled.\n"
     ]
    }
   ],
   "source": [
    "# Scale the Data\n",
    "if data is not None:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    print(\"Data scaled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7af7503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the heart disease model...\n",
      "Model trained.\n"
     ]
    }
   ],
   "source": [
    "# Create and Train the Logistic Regression Model\n",
    "if data is not None:\n",
    "    print(\"Training the heart disease model...\")\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    print(\"Model trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7707c80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy on Test Data: 90.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model\n",
    "if data is not None:\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"Model Accuracy on Test Data: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e452508c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../models\\heart_disease_model.pkl\n",
      "Scaler saved to ../models\\heart_disease_scaler.pkl\n",
      "Model columns saved to ../models\\heart_disease_model_columns.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the Model, Scaler, and Column List\n",
    "if data is not None:\n",
    "    MODEL_DIR = '../models'\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    \n",
    "    model_filename = os.path.join(MODEL_DIR, 'heart_disease_model.pkl')\n",
    "    scaler_filename = os.path.join(MODEL_DIR, 'heart_disease_scaler.pkl')\n",
    "    columns_filename = os.path.join(MODEL_DIR, 'heart_disease_model_columns.pkl')\n",
    "    \n",
    "    # Save the model\n",
    "    joblib.dump(model, model_filename)\n",
    "    \n",
    "    # Save the scaler\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    \n",
    "    # Save the column list (critical for the API)\n",
    "    model_columns = list(X.columns)\n",
    "    joblib.dump(model_columns, columns_filename)\n",
    "\n",
    "    print(f\"Model saved to {model_filename}\")\n",
    "    print(f\"Scaler saved to {scaler_filename}\")\n",
    "    print(f\"Model columns saved to {columns_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "healthCare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
